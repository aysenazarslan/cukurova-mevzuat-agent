import json
import pandas as pd
import sys
import os
import time
from tqdm import tqdm
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

# --- AYARLAR ---
load_dotenv()
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

if not DEEPSEEK_API_KEY:
    print("âŒ HATA: .env dosyasÄ±nda DEEPSEEK_API_KEY bulunamadÄ±!")
    sys.exit(1)

MODEL_NAME = "deepseek-chat"
BASE_URL = "https://api.deepseek.com"

current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

try:
    from src import config
    CHROMA_PATH = config.CHROMA_DB_DIR
    EMBEDDING_MODEL = config.EMBEDDING_MODEL_NAME
except ImportError:
    CHROMA_PATH = os.path.join(parent_dir, "data", "chroma_db")
    EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

BENCHMARK_FILE = os.path.join(current_dir, 'benchmark_data.json')
OUTPUT_EXCEL = os.path.join(current_dir, 'deepseek_final_sonuc.xlsx')

# --- FONKSÄ°YONLAR ---

def get_deepseek_answer(question, vector_db):
    # DÃœZELTME: k=20 (Ä°deal Denge). Sistemi yormaz ama cevabÄ± bulur.
    docs = vector_db.similarity_search(question, k=20)
    
    if not docs: return "Bilgi bulunamadÄ±."
    
    context_text = ""
    for i, d in enumerate(docs):
        context_text += f"\n--- PARÃ‡A {i+1} ---\n{d.page_content}\n"
    
    llm = ChatOpenAI(
        model=MODEL_NAME,
        openai_api_key=DEEPSEEK_API_KEY,
        openai_api_base=BASE_URL,
        temperature=0 # SÄ±fÄ±r hata toleransÄ±
    )
    
    prompt = ChatPromptTemplate.from_template("""
    Sen Ã‡ukurova Ãœniversitesi mevzuat asistanÄ±sÄ±n.
    AÅŸaÄŸÄ±daki dÃ¶kÃ¼manlarÄ± kullanarak soruyu NET ve KISA bir ÅŸekilde cevapla.
    
    KURALLAR:
    1. Sadece verilen metne sadÄ±k kal.
    2. EÄŸer metinde cevap yoksa "YÃ¶netmelikte bulunamadÄ±" de.
    3. SayÄ±sal verileri (kredi, yÄ±l, gÃ¼n) asla kaÃ§Ä±rma.
    
    DÃ–KÃœMANLAR:
    {context}
    
    SORU: {question}
    
    CEVAP:
    """)
    chain = prompt | llm
    
    try:
        response = chain.invoke({"context": context_text, "question": question})
        return response.content
    except Exception as e:
        # Hata varsa terminale bas (Gizleme)
        print(f"\nâš ï¸  CEVAP ÃœRETME HATASI: {e}")
        return f"HATA: {str(e)}"

def evaluate_with_deepseek(soru, dogru, cevap):
    if "HATA" in cevap: return 0, "Sistem HatasÄ±"
    
    llm = ChatOpenAI(
        model=MODEL_NAME,
        openai_api_key=DEEPSEEK_API_KEY,
        openai_api_base=BASE_URL,
        temperature=0
    )
    
    prompt = ChatPromptTemplate.from_template("""
    Sen Ã¶ÄŸretmensin. CevabÄ± puanla (1-5).
    
    SORU: {soru}
    REFERANS: {dogru}
    Ã–ÄRENCÄ°: {cevap}
    
    Format:
    PUAN: [Rakam]
    GEREKÃ‡E: [KÄ±sa aÃ§Ä±klama]
    """)
    chain = prompt | llm
    
    try:
        response = chain.invoke({"soru": soru, "dogru": dogru, "cevap": cevap})
        text = response.content
        import re
        puan_match = re.search(r'PUAN:\s*(\d)', text)
        puan = int(puan_match.group(1)) if puan_match else 1
        
        gerekce_match = re.search(r'GEREKÃ‡E:\s*(.*)', text, re.DOTALL)
        gerekce = gerekce_match.group(1).strip() if gerekce_match else text.strip()
        
        return puan, gerekce
    except Exception as e:
        print(f"\nâš ï¸  HAKEM HATASI: {e}")
        return 3, "Format hatasÄ±"

# --- TABLO ---
def print_table(results):
    print("\n" + "="*140)
    print(f"{'ID':<3} | {'SORU':<35} | {'PUAN':<4} | {'DURUM':<10} | {'HAKEM GEREKÃ‡ESÄ°'}")
    print("-" * 140)
    for r in results:
        soru_ozet = (r['Soru'][:32] + "..") if len(r['Soru']) > 32 else r['Soru']
        # GerekÃ§eyi temizle (yeni satÄ±rlarÄ± sil)
        temiz_gerekce = r['GerekÃ§e'].replace('\n', ' ')
        gerekce_ozet = (temiz_gerekce[:75] + "..") if len(temiz_gerekce) > 75 else temiz_gerekce
        
        print(f"{r['ID']:<3} | {soru_ozet:<35} | {r['Puan']:<4} | {r['Durum']:<10} | {gerekce_ozet}")
    print("="*140 + "\n")

# --- ANA PROGRAM ---
def main():
    print(f"\n DEEPSEEK DENGELÄ° MOD (k=20) BAÅLIYOR")
    print("---------------------------------------")

    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    vector_db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)
    
    with open(BENCHMARK_FILE, 'r', encoding='utf-8') as f:
        questions = json.load(f)

    results = []
    # TQDM ayarlarÄ±
    pbar = tqdm(questions, desc="Analiz", bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}]")
    
    for i, item in enumerate(pbar):
        soru = item['question']
        dogru = item['ground_truth']
        
        # Cevapla
        cevap = get_deepseek_answer(soru, vector_db)
        
        # Puanla
        puan, gerekce = evaluate_with_deepseek(soru, dogru, cevap)
        
        # Debug BaskÄ±sÄ± (EÄŸer puan dÃ¼ÅŸÃ¼kse nedenini hemen gÃ¶relim)
        if puan < 3:
            tqdm.write(f"\n DÃ¼ÅŸÃ¼k Puan ({puan}): {soru[:50]}...")
            tqdm.write(f"   Cevap: {cevap[:100]}...")
        
        results.append({
            "ID": item.get('id', i+1),
            "Soru": soru,
            "Cevap": cevap,
            "Referans": dogru,
            "Puan": puan,
            "GerekÃ§e": gerekce,
            "Durum": "BAÅARILI âœ…" if puan >= 3 else "BAÅARISIZ âŒ"
        })
        
        df = pd.DataFrame(results)
        df.to_excel(OUTPUT_EXCEL, index=False)
        
        if len(df) > 0:
            basari = len(df[df["Puan"] >= 3])
            oran = (basari / len(df)) * 100
            pbar.set_postfix({"BaÅŸarÄ±": f"%{oran:.0f}"})

    print_table(results)
    
    basari_sayisi = len([r for r in results if r['Puan'] >= 3])
    final_oran = (basari_sayisi / len(results)) * 100
    
    print(f"\nğŸ† FÄ°NAL SKOR: %{final_oran:.2f}")

if __name__ == "__main__":
    main()